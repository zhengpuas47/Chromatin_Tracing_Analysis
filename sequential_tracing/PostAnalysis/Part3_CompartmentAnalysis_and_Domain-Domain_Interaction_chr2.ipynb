{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This a jupyter notebook guide on compartment analysis for chr2 and the domain-domain interaction on chr2\n",
    "\n",
    "by Pu Zheng and Bogdan Bintu\n",
    "\n",
    "2020.06.06\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import sys, os, glob, time, copy\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pickle\n",
    "\n",
    "sys.path.append(os.path.abspath(r\"..\\.\"))\n",
    "\n",
    "import source as ia\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.spatial.distance import cdist,pdist,squareform\n",
    "\n",
    "print(os.getpid()) # print this so u can terminate through cmd / task-manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required plotting setting\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', family='serif')\n",
    "plt.rc('font', serif='Arial')\n",
    "_font_size = 7.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required plotting parameters\n",
    "from source.figure_tools import _dpi,_single_col_width,_double_col_width,_single_row_height,_ref_bar_length, _ticklabel_size,_ticklabel_width,_font_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure folder\n",
    "parent_figure_folder = r'\\\\10.245.74.158\\Chromatin_NAS_4\\Chromatin_Share\\final_figures'\n",
    "figure_folder = os.path.join(parent_figure_folder, 'Chr2_figures')\n",
    "print(figure_folder)\n",
    "if not os.path.exists(figure_folder):\n",
    "    os.makedirs(figure_folder)\n",
    "    print(\"generating this folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = r'E:\\Users\\puzheng\\Dropbox\\2020 Chromatin Imaging Manuscript\\Revision\\DataForReviewers'\n",
    "rep1_filename = os.path.join(data_folder, 'chromosome2.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 load replicate 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from file and extract info\n",
    "import csv\n",
    "rep1_info_dict = {}\n",
    "with open(rep1_filename, 'r') as _handle:\n",
    "    _reader = csv.reader(_handle, delimiter='\\t', quotechar='|')\n",
    "    _headers = next(_reader)\n",
    "    print(_headers)\n",
    "    # create keys for each header\n",
    "    for _h in _headers:\n",
    "        rep1_info_dict[_h] = []\n",
    "    # loop through content\n",
    "    for _contents in _reader:\n",
    "        for _h, _info in zip(_headers,_contents):\n",
    "            rep1_info_dict[_h].append(_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# clean up infoa\n",
    "data_rep1 = {'params':{}}\n",
    "\n",
    "# clean up genomic coordiantes\n",
    "region_names = np.array([_n for _n in sorted(np.unique(rep1_info_dict['Genomic coordinate']), \n",
    "                                             key=lambda s:int(s.split(':')[1].split('-')[0]))])\n",
    "region_starts = np.array([int(_n.split(':')[1].split('-')[0]) for _n in region_names])\n",
    "region_ends = np.array([int(_n.split(':')[1].split('-')[1]) for _n in region_names])[np.argsort(region_starts)]\n",
    "region_starts = np.sort(region_starts)\n",
    "\n",
    "mid_positions = ((region_starts + region_ends)/2).astype(np.int)\n",
    "mid_positions_Mb = np.round(mid_positions / 1e6, 2) \n",
    "\n",
    "# clean up chrom copy number\n",
    "chr_nums = np.array([int(_info) for _info in rep1_info_dict['Chromosome copy number']])\n",
    "chr_ids, region_cts = np.unique(chr_nums, return_counts=True)\n",
    "dna_zxys_list = [[[] for _start in region_starts] for _id in chr_ids]\n",
    "\n",
    "# clean up zxy\n",
    "for _z,_x,_y,_reg_info, _cid in tqdm(zip(rep1_info_dict['Z(nm)'],rep1_info_dict['X(nm)'],\\\n",
    "                                         rep1_info_dict['Y(nm)'],rep1_info_dict['Genomic coordinate'],\\\n",
    "                                         rep1_info_dict['Chromosome copy number'])):\n",
    "    # get chromosome inds\n",
    "    _cid = int(_cid)\n",
    "    _cind = np.where(chr_ids == _cid)[0][0]\n",
    "    \n",
    "    # get region indices\n",
    "    _start = int(_reg_info.split(':')[1].split('-')[0])\n",
    "    _rind = np.where(region_starts==_start)[0][0]\n",
    "    \n",
    "    dna_zxys_list[_cind][_rind] = np.array([float(_z),float(_x), float(_y)])\n",
    "\n",
    "# merge together\n",
    "dna_zxys_list = np.array(dna_zxys_list)\n",
    "data_rep1['chrom_ids'] = chr_ids\n",
    "data_rep1['region_names'] = region_names\n",
    "data_rep1['mid_position_Mb'] = mid_positions_Mb\n",
    "data_rep1['dna_zxys'] = dna_zxys_list\n",
    "\n",
    "# clean up tss and transcription\n",
    "if 'Gene names' in rep1_info_dict:\n",
    "    import re\n",
    "    # first extract number of genes\n",
    "    gene_names = []\n",
    "    for _gene_info, _trans_info, _tss_coord in zip(rep1_info_dict['Gene names'],\n",
    "                                                   rep1_info_dict['Transcription'],\n",
    "                                                   rep1_info_dict['TSS ZXY(nm)']):\n",
    "        if _gene_info != '':\n",
    "            # split by semicolon\n",
    "            _genes = _gene_info.split(';')[:-1]\n",
    "            for _gene in _genes:\n",
    "                if _gene not in gene_names:\n",
    "                    gene_names.append(_gene)\n",
    "    print(f\"{len(gene_names)} genes exist in this dataset.\")\n",
    "    \n",
    "    # initialize gene and transcription\n",
    "    tss_zxys_list = [[[] for _gene in gene_names] for _id in chr_ids]\n",
    "    transcription_profiles = [[[] for _gene in gene_names] for _id in chr_ids]\n",
    "    # loop through to get info\n",
    "    for _cid, _gene_info, _trans_info, _tss_locations in tqdm(zip(rep1_info_dict['Chromosome copy number'],\n",
    "                                                                  rep1_info_dict['Gene names'],\n",
    "                                                                  rep1_info_dict['Transcription'],\n",
    "                                                                  rep1_info_dict['TSS ZXY(nm)'])):\n",
    "        # get chromosome inds\n",
    "        _cid = int(_cid)\n",
    "        _cind = np.where(chr_ids == _cid)[0][0]\n",
    "        # process if there are genes in this region:\n",
    "        if _gene_info != '':\n",
    "            # split by semicolon\n",
    "            _genes = _gene_info.split(';')[:-1]\n",
    "            _transcribes = _trans_info.split(';')[:-1]\n",
    "            _tss_zxys = _tss_locations.split(';')[:-1]\n",
    "            for _gene, _transcribe, _tss_zxy in zip(_genes, _transcribes, _tss_zxys):\n",
    "                # get gene index\n",
    "                _gind = gene_names.index(_gene)\n",
    "                # get transcription profile\n",
    "                if _transcribe == 'on':\n",
    "                    transcription_profiles[_cind][_gind] = True\n",
    "                else:\n",
    "                    transcription_profiles[_cind][_gind] = False\n",
    "                # get coordinates\n",
    "                _tss_zxy = np.array([np.float(_c) for _c in re.split(r'\\s+', _tss_zxy.split('[')[1].split(']')[0]) if _c != ''])\n",
    "                tss_zxys_list[_cind][_gind] = _tss_zxy\n",
    "                \n",
    "    tss_zxys_list = np.array(tss_zxys_list)\n",
    "    transcription_profiles = np.array(transcription_profiles)\n",
    "    data_rep1['gene_names'] = gene_names\n",
    "    data_rep1['tss_zxys'] = tss_zxys_list\n",
    "    data_rep1['trans_pfs'] = transcription_profiles\n",
    "\n",
    "# clean up cell_cycle states\n",
    "if 'Cell cycle state' in rep1_info_dict:\n",
    "    cell_cycle_types = np.unique(rep1_info_dict['Cell cycle state'])\n",
    "    cell_cycle_flag_dict = {_k:[[] for _id in chr_ids] for _k in cell_cycle_types if _k != 'ND'}\n",
    "    for _cid, _state in tqdm(zip(rep1_info_dict['Chromosome copy number'],rep1_info_dict['Cell cycle state'])):\n",
    "        # get chromosome inds\n",
    "        _cid = int(_cid)\n",
    "        _cind = np.where(chr_ids == _cid)[0][0]\n",
    "        if np.array([_v[_cind]==[] for _k,_v in cell_cycle_flag_dict.items()]).any():\n",
    "            for _k,_v in cell_cycle_flag_dict.items():\n",
    "                if _k == _state:\n",
    "                    _v[_cind] = True\n",
    "                else:\n",
    "                    _v[_cind] = False\n",
    "    # append to data\n",
    "    for _k, _v in cell_cycle_flag_dict.items():\n",
    "        data_rep1[f'{_k}_flags'] = np.array(_v)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get population averaged maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P and q arm crop\n",
    "p_crop = slice(0, 357)\n",
    "q_crop = slice(357, len(data_rep1['dna_zxys'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p_crop, q_crop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Population-averaged maps for chr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zxys_rep1_list = np.array(data_rep1['dna_zxys'])\n",
    "distmap_rep1_list = np.array([squareform(pdist(_zxy)) for _zxy in zxys_rep1_list])\n",
    "# calculate contact freq map\n",
    "contact_th = 500\n",
    "contact_rep1_map = np.sum(distmap_rep1_list<contact_th, axis=0) / np.sum(np.isnan(distmap_rep1_list)==False, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## corresponding Hi-C data from Rao et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hic_filename = os.path.join(data_folder, 'Hi-C matrices', 'Hi-C_contacts_chromosome2.tsv')\n",
    "\n",
    "hic_map = []\n",
    "\n",
    "with open(hic_filename, 'r') as _handle:\n",
    "    _reader = csv.reader(_handle, delimiter='\\t', quotechar='|')\n",
    "    col_regions = next(_reader)[1:]\n",
    "    row_regions = []\n",
    "    # loop through content\n",
    "    for _contents in _reader:\n",
    "        row_regions.append(_contents[0])\n",
    "        hic_map.append([float(_c) for _c in _contents[1:]])\n",
    "hic_map = np.array(hic_map)\n",
    "# sort row and col to match tsv dataset\n",
    "row_order = np.concatenate([np.where(data_rep1['region_names']==_rn)[0] for _rn in row_regions])\n",
    "col_order = np.concatenate([np.where(data_rep1['region_names']==_cn)[0] for _cn in col_regions])\n",
    "hic_map = hic_map[row_order][:, col_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chr2 proximity frequency map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.figure_tools.distmap import plot_distance_map\n",
    "print(figure_folder)\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "contact_limits = [0.006, 0.6]\n",
    "contact_norm = LogNorm(vmin=np.min(contact_limits), \n",
    "                       vmax=np.max(contact_limits))\n",
    "contact_cmap = matplotlib.cm.get_cmap('seismic')\n",
    "contact_cmap.set_bad(color=[0.,0.,0.,1])\n",
    "\n",
    "contact_ax = plot_distance_map(contact_rep1_map, \n",
    "                               cmap=contact_cmap,\n",
    "                               color_limits=contact_limits,\n",
    "                               color_norm=contact_norm,\n",
    "                               tick_labels=data_rep1['mid_position_Mb'], \n",
    "                               ax_label='Genomic positions (Mb)', \n",
    "                               colorbar_labels='Proximity frequency',\n",
    "                               save=True, save_folder=figure_folder, \n",
    "                               save_basename=f'FigS2E1_chr2_proximity_freq_map_new.pdf',\n",
    "                               font_size=5)\n",
    "\n",
    "\n",
    "hic_limits = [0.1, 300]\n",
    "hic_norm = LogNorm(vmin=np.min(hic_limits), \n",
    "                   vmax=np.max(hic_limits))\n",
    "hic_cmap = matplotlib.cm.get_cmap('seismic')\n",
    "hic_cmap.set_bad(color=[0.,0.,0.,1])\n",
    "\n",
    "hic_ax = plot_distance_map(hic_map, \n",
    "                           cmap=hic_cmap,\n",
    "                           color_limits=hic_limits,\n",
    "                           color_norm=hic_norm,\n",
    "                           tick_labels=data_rep1['mid_position_Mb'], \n",
    "                           ax_label='Genomic positions (Mb)', \n",
    "                           colorbar_labels='Hi-C count',\n",
    "                           save=True, save_folder=figure_folder, \n",
    "                           save_basename=f'FigS2E2_chr2_Hi-C_map_new.pdf',\n",
    "                           font_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 compartment calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PC1 barplot for p and q arm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## p-arm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do PCA\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_sigma = 1\n",
    "hic_sigma = 0.25\n",
    "\n",
    "# normalize genomic distance effects\n",
    "genomic_distance_map = squareform(pdist(data_rep1['mid_position_Mb'][:,np.newaxis]))\n",
    "genomic_distance_entries = genomic_distance_map[np.triu_indices(len(genomic_distance_map),1)]\n",
    "\n",
    "## p arm, proximity\n",
    "p_gd_map = genomic_distance_map[p_crop, p_crop]\n",
    "p_contact_rep1_map = contact_rep1_map[p_crop, p_crop]\n",
    "# normalize genomic distance effect\n",
    "genomic_distance_entries = p_gd_map[np.triu_indices(len(p_gd_map),1)]\n",
    "contact_entries = p_contact_rep1_map[np.triu_indices(len(p_contact_rep1_map),1)]\n",
    "p_contact_kept = (genomic_distance_entries > 0) * (contact_entries > 0)\n",
    "p_contact_lr = scipy.stats.linregress(np.log(genomic_distance_entries[p_contact_kept]), \n",
    "                                      np.log(contact_entries[p_contact_kept]))\n",
    "print(p_contact_lr)\n",
    "p_normalization_mat = np.exp(np.log(p_gd_map) * p_contact_lr.slope + p_contact_lr.intercept)\n",
    "for _i in range(len(p_normalization_mat)):\n",
    "    p_normalization_mat[_i,_i] = 1\n",
    "p_normed_contact_rep1_map = p_contact_rep1_map / p_normalization_mat\n",
    "# apply gaussian\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "p_contact_corr_rep1_map = np.corrcoef(gaussian_filter(p_normed_contact_rep1_map, gaussian_sigma))\n",
    "# PCA\n",
    "p_contact_model_rep1 = PCA(1)\n",
    "p_contact_model_rep1.fit(p_contact_corr_rep1_map)\n",
    "p_contact_pc1_rep1 = np.reshape(p_contact_model_rep1.fit_transform(p_contact_corr_rep1_map), -1)\n",
    "\n",
    "## p arm, Hi-C\n",
    "p_gd_map = genomic_distance_map[p_crop, p_crop]\n",
    "p_hic_map = hic_map[p_crop, p_crop]\n",
    "# normalize genomic distance effects\n",
    "genomic_distance_entries = p_gd_map[np.triu_indices(len(p_gd_map),1)]\n",
    "hic_entries = p_hic_map[np.triu_indices(len(p_hic_map),1)]\n",
    "p_hic_kept = (genomic_distance_entries > 0) * (hic_entries > 0)\n",
    "p_hic_lr = scipy.stats.linregress(np.log(genomic_distance_entries[p_hic_kept]), \n",
    "                              np.log(hic_entries[p_hic_kept]))\n",
    "print(p_hic_lr)\n",
    "p_normalization_mat = np.exp(np.log(p_gd_map) * p_hic_lr.slope + p_hic_lr.intercept)\n",
    "#for _i in range(len(p_normalization_mat)):\n",
    "#    p_normalization_mat[_i,_i] = 1\n",
    "p_normed_hic_map = p_hic_map / p_normalization_mat\n",
    "# apply gaussian\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "p_hic_corr_map = np.corrcoef(gaussian_filter(p_normed_hic_map, hic_sigma))\n",
    "# PCA\n",
    "p_hic_model = PCA(1)\n",
    "p_hic_model.fit(p_hic_corr_map)\n",
    "p_hic_pc1 = np.reshape(p_hic_model.fit_transform(p_hic_corr_map), -1)\n",
    "\n",
    "\n",
    "# Plot vs. Hi-C\n",
    "## pc1 barplot\n",
    "fig, ax = plt.subplots(figsize=(_double_col_width, _single_col_width), dpi=600)\n",
    "grid = plt.GridSpec(2, 1, height_ratios=[1,1], hspace=0., wspace=0.)\n",
    "contact_ax = plt.subplot(grid[0])\n",
    "contact_ax.bar(np.where(p_contact_pc1_rep1>=0)[0],\n",
    "               p_contact_pc1_rep1[p_contact_pc1_rep1>=0],\n",
    "               width=1, color='r', label='A')\n",
    "contact_ax.bar(np.where(p_contact_pc1_rep1<0)[0],\n",
    "               p_contact_pc1_rep1[p_contact_pc1_rep1<0],\n",
    "               width=1, color='b', label='B')\n",
    "contact_ax.tick_params('both', labelsize=_font_size, \n",
    "            width=_ticklabel_width, length=_ticklabel_size,\n",
    "            pad=1,labelbottom=False) # remove bottom ticklabels for ax1\n",
    "[i[1].set_linewidth(_ticklabel_width) for i in contact_ax.spines.items()]\n",
    "contact_ax.set_ylim([-12,12])\n",
    "contact_ax.set_yticks([-10,0,10])\n",
    "contact_ax.set_ylabel(\"Contact PC1\", fontsize=_font_size, labelpad=0)\n",
    "\n",
    "# hic-ax\n",
    "hic_ax = plt.subplot(grid[1], sharex=contact_ax)\n",
    "\n",
    "hic_ax.bar(np.where(p_hic_pc1>=0)[0],\n",
    "               p_hic_pc1[p_hic_pc1>=0],\n",
    "               width=1, color='r', label='A')\n",
    "hic_ax.bar(np.where(p_hic_pc1<0)[0],\n",
    "               p_hic_pc1[p_hic_pc1<0],\n",
    "               width=1, color='b', label='B')\n",
    "hic_ax.tick_params('both', labelsize=_font_size, \n",
    "            width=_ticklabel_width, length=_ticklabel_size,\n",
    "            pad=1,) # remove bottom ticklabels for ax1\n",
    "[i[1].set_linewidth(_ticklabel_width) for i in hic_ax.spines.items()]\n",
    "hic_ax.set_ylim([-12,12])\n",
    "hic_ax.set_yticks([-10,0,10])\n",
    "hic_ax.set_ylabel(\"Hi-C PC1\", fontsize=_font_size, labelpad=0)\n",
    "\n",
    "# set x\n",
    "hic_ax.set_xlim([0, len(p_contact_pc1_rep1)])\n",
    "_xticks = [0, len(p_contact_pc1_rep1)-1]\n",
    "hic_ax.set_xticks(_xticks)\n",
    "hic_ax.set_xticklabels(data_rep1['mid_position_Mb'][_xticks])\n",
    "hic_ax.set_xlabel(f'Genomic Positions (Mb)', fontsize=_font_size, labelpad=1)\n",
    "\n",
    "plt.gcf().subplots_adjust(bottom=0.15, left=0.1)\n",
    "\n",
    "plt.savefig(os.path.join(figure_folder, f'FigS2F1_chr2_p_arm_PC1_barplot_rep1.pdf'), transparent=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## q-arm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_sigma = 1\n",
    "hic_sigma = 0.25\n",
    "\n",
    "## q arm, proximity\n",
    "q_gd_map = genomic_distance_map[q_crop, q_crop]\n",
    "q_contact_rep1_map = contact_rep1_map[q_crop, q_crop]\n",
    "# normalize genomic distance effects\n",
    "genomic_distance_entries = q_gd_map[np.triu_indices(len(q_gd_map),1)]\n",
    "contact_entries = q_contact_rep1_map[np.triu_indices(len(q_contact_rep1_map),1)]\n",
    "q_contact_kept = (genomic_distance_entries > 0) * (contact_entries > 0)\n",
    "q_contact_lr = scipy.stats.linregress(np.log(genomic_distance_entries[q_contact_kept]), \n",
    "                              np.log(contact_entries[q_contact_kept]))\n",
    "print(q_contact_lr)\n",
    "q_normalization_mat = np.exp(np.log(q_gd_map) * q_contact_lr.slope + q_contact_lr.intercept)\n",
    "#for _i in range(len(q_normalization_mat)):\n",
    "#    q_normalization_mat[_i,_i] = 1\n",
    "q_normed_contact_rep1_map = q_contact_rep1_map / q_normalization_mat\n",
    "# apply gaussian\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "q_contact_corr_rep1_map = np.corrcoef(gaussian_filter(q_normed_contact_rep1_map, gaussian_sigma))\n",
    "\n",
    "# Do PCA\n",
    "q_contact_model_rep1 = PCA(1)\n",
    "q_contact_model_rep1.fit(q_contact_corr_rep1_map)\n",
    "q_contact_pc1_rep1 = np.reshape(q_contact_model_rep1.fit_transform(q_contact_corr_rep1_map), -1)\n",
    "\n",
    "## q arm, Hi-C\n",
    "q_gd_map = genomic_distance_map[q_crop, q_crop]\n",
    "q_hic_map = hic_map[q_crop, q_crop]\n",
    "# normalize genomic distance effects\n",
    "genomic_distance_entries = q_gd_map[np.triu_indices(len(q_gd_map),1)]\n",
    "hic_entries = q_hic_map[np.triu_indices(len(q_hic_map),1)]\n",
    "q_hic_kept = (genomic_distance_entries > 0) * (hic_entries > 0)\n",
    "q_hic_lr = scipy.stats.linregress(np.log(genomic_distance_entries[q_hic_kept]), \n",
    "                              np.log(hic_entries[q_hic_kept]))\n",
    "print(q_hic_lr)\n",
    "q_normalization_mat = np.exp(np.log(q_gd_map) * q_hic_lr.slope + q_hic_lr.intercept)\n",
    "#for _i in range(len(q_normalization_mat)):\n",
    "#    q_normalization_mat[_i,_i] = 1\n",
    "q_normed_hic_map = q_hic_map / q_normalization_mat\n",
    "# apply gaussian\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "q_hic_corr_map = np.corrcoef(gaussian_filter(q_normed_hic_map, hic_sigma))\n",
    "# PCA\n",
    "q_hic_model = PCA(1)\n",
    "q_hic_model.fit(q_hic_corr_map)\n",
    "q_hic_pc1 = np.reshape(q_hic_model.fit_transform(q_hic_corr_map), -1)\n",
    "\n",
    "# plot vs. Hi-C\n",
    "## pc1 barplot\n",
    "fig, ax = plt.subplots(figsize=(_double_col_width, _single_col_width), dpi=600)\n",
    "grid = plt.GridSpec(2, 1, height_ratios=[1,1], hspace=0., wspace=0.)\n",
    "contact_ax = plt.subplot(grid[0])\n",
    "contact_ax.bar(np.where(q_contact_pc1_rep1>=0)[0],\n",
    "               q_contact_pc1_rep1[q_contact_pc1_rep1>=0],\n",
    "               width=1, color='r', label='A')\n",
    "contact_ax.bar(np.where(q_contact_pc1_rep1<0)[0],\n",
    "               q_contact_pc1_rep1[q_contact_pc1_rep1<0],\n",
    "               width=1, color='b', label='B')\n",
    "contact_ax.tick_params('both', labelsize=_font_size, \n",
    "            width=_ticklabel_width, length=_ticklabel_size,\n",
    "            pad=1,labelbottom=False) # remove bottom ticklabels for ax1\n",
    "[i[1].set_linewidth(_ticklabel_width) for i in contact_ax.spines.items()]\n",
    "\n",
    "contact_ax.set_ylabel(\"Contact PC1\", fontsize=_font_size, labelpad=0)\n",
    "contact_ax.set_ylim([-12,12])\n",
    "contact_ax.set_yticks([-10,0,10])\n",
    "\n",
    "# hic-ax\n",
    "hic_ax = plt.subplot(grid[1], sharex=contact_ax)\n",
    "\n",
    "hic_ax.bar(np.where(q_hic_pc1>=0)[0],\n",
    "               q_hic_pc1[q_hic_pc1>=0],\n",
    "               width=1, color='r', label='A')\n",
    "hic_ax.bar(np.where(q_hic_pc1<0)[0],\n",
    "               q_hic_pc1[q_hic_pc1<0],\n",
    "               width=1, color='b', label='B')\n",
    "hic_ax.tick_params('both', labelsize=_font_size, \n",
    "            width=_ticklabel_width, length=_ticklabel_size,\n",
    "            pad=1,) # remove bottom ticklabels for ax1\n",
    "[i[1].set_linewidth(_ticklabel_width) for i in hic_ax.spines.items()]\n",
    "\n",
    "hic_ax.set_ylabel(\"Hi-C PC1\", fontsize=_font_size, labelpad=0)\n",
    "hic_ax.set_ylim([-12,12])\n",
    "hic_ax.set_yticks([-10,0,10])\n",
    "\n",
    "# set x\n",
    "hic_ax.set_xlim([0, len(q_contact_pc1_rep1)])\n",
    "_xticks = [0, len(q_contact_pc1_rep1)-1]\n",
    "hic_ax.set_xticks(_xticks)\n",
    "hic_ax.set_xticklabels(data_rep1['mid_position_Mb'][np.array(_xticks)+q_crop.start])\n",
    "hic_ax.set_xlabel(f'Genomic Positions (Mb)', fontsize=_font_size, labelpad=1)\n",
    "\n",
    "plt.gcf().subplots_adjust(bottom=0.15, left=0.1)\n",
    "\n",
    "plt.savefig(os.path.join(figure_folder, f'FigS2F2_chr2_q_arm_PC1_barplot_rep1.pdf'), transparent=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finalize AB calling\n",
    "\n",
    "Merge small compartments with, which is ~1Mb in chr2 case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_p_AB_dict = {'A': np.where(p_contact_pc1_rep1 >= 0)[0], \n",
    "                  'B': np.where(p_contact_pc1_rep1 < 0)[0], \n",
    "                  } \n",
    "temp_q_AB_dict = {'A': np.where(q_contact_pc1_rep1 >= 0)[0]+q_crop.start, \n",
    "                  'B': np.where(q_contact_pc1_rep1 < 0)[0]+q_crop.start, \n",
    "                  } \n",
    "temp_AB_dict = {'A':np.concatenate([temp_p_AB_dict['A'],temp_q_AB_dict['A']]),\n",
    "                'B':np.concatenate([temp_p_AB_dict['B'],temp_q_AB_dict['B']]),}\n",
    "\n",
    "temp_AB_vector = np.ones(len(zxys_rep1_list[0])).astype(np.int) * -1\n",
    "temp_AB_vector[temp_AB_dict['A']] = 1\n",
    "temp_AB_vector[temp_AB_dict['B']] = 0\n",
    "\n",
    "num_small_compartment = np.inf\n",
    "prev_v = temp_AB_vector[0]\n",
    "while num_small_compartment > 0:\n",
    "    # find indices for all sub-comaprtments\n",
    "    all_comp_inds = []\n",
    "    _comp_inds = []\n",
    "    prev_v = temp_AB_vector[0] # initialize previous compartment\n",
    "    for _i, _v in enumerate(temp_AB_vector):\n",
    "        if prev_v != _v:\n",
    "            all_comp_inds.append(_comp_inds)\n",
    "            _comp_inds = [_i]\n",
    "        else:\n",
    "            _comp_inds.append(_i)            \n",
    "        prev_v = _v\n",
    "    if _comp_inds != []:\n",
    "        all_comp_inds.append(_comp_inds)\n",
    "    # calculate length of each compartment\n",
    "    all_comp_lens = np.array([len(_c) for _c in all_comp_inds])\n",
    "    # update number of small comparment\n",
    "    num_small_compartment = np.sum(all_comp_lens < 4)\n",
    "    print(all_comp_lens, num_small_compartment)\n",
    "    # choose the smallest compartment to flip its AB\n",
    "    flip_ind = np.argmin(all_comp_lens)\n",
    "    temp_AB_vector[np.array(all_comp_inds[flip_ind])] = 1 - temp_AB_vector[np.array(all_comp_inds[flip_ind])]\n",
    "    \n",
    "# based on this cleaned AB_vector, recreate AB_dict\n",
    "data_rep1['AB_dict'] = {\n",
    "    'A': np.where(temp_AB_vector==1)[0],\n",
    "    'B': np.where(temp_AB_vector==0)[0],\n",
    "}\n",
    "data_rep1['p_AB_dict'] = {\n",
    "    'A': np.where(temp_AB_vector[p_crop]==1)[0]+p_crop.start,\n",
    "    'B': np.where(temp_AB_vector[p_crop]==0)[0]+p_crop.start,\n",
    "}\n",
    "data_rep1['q_AB_dict'] = {\n",
    "    'A': np.where(temp_AB_vector[q_crop]==1)[0]+q_crop.start,\n",
    "    'B': np.where(temp_AB_vector[q_crop]==0)[0]+q_crop.start,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation matrix for proximity frequency map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lims = [0,len(p_contact_corr_rep1_map)]\n",
    "\n",
    "xlims = np.array([min(lims), max(lims)])\n",
    "ylims = np.array([min(lims), max(lims)])\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "domain_line_color = [1,1,0,1]\n",
    "domain_line_width = 1.5\n",
    "bad_color=[0,0,0,1]\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(_single_col_width, _single_col_width), dpi=600)\n",
    "\n",
    "# create a color map\n",
    "current_cmap = matplotlib.cm.get_cmap('seismic')\n",
    "current_cmap.set_bad(color=[0.5,0.5,0.5,1])\n",
    "\n",
    "_pf = ax1.imshow(p_contact_corr_rep1_map, cmap=current_cmap, vmin=-1, vmax=1)\n",
    "\n",
    "ax1.tick_params('both', labelsize=_font_size, \n",
    "                width=_ticklabel_width, length=0,\n",
    "                pad=1, labelleft=False, labelbottom=False) # remove bottom ticklabels for ax1\n",
    "[i[1].set_linewidth(_ticklabel_width) for i in ax1.spines.items()]\n",
    "\n",
    "\n",
    "# locate ax1\n",
    "divider = make_axes_locatable(ax1)\n",
    "\n",
    "# colorbar ax\n",
    "cax = divider.append_axes('right', size='6%', pad=\"4%\")\n",
    "cbar = plt.colorbar(_pf,cax=cax, ax=ax1, ticks=[-1,1])\n",
    "cbar.ax.tick_params('both', labelsize=_font_size, \n",
    "                width=_ticklabel_width, length=_ticklabel_size-1,\n",
    "                pad=1, labelleft=False) # remove bottom ticklabels for ax1\n",
    "cbar.outline.set_linewidth(_ticklabel_width)\n",
    "cbar.set_label('Pearson correlation', \n",
    "               fontsize=_font_size, labelpad=0, rotation=270)\n",
    "\n",
    "# create bottom ax\n",
    "bot_ax = divider.append_axes('bottom', size='10%', pad=\"0%\", \n",
    "                             sharex=ax1, xticks=[])\n",
    "bot_ax.bar(data_rep1['p_AB_dict']['A'], height=1, color='r', width=1, label='A')\n",
    "bot_ax.bar(data_rep1['p_AB_dict']['B'], height=-1, color='b', width=1, label='B')\n",
    "bot_ax.set_yticks([])\n",
    "bot_ax.set_yticklabels([])\n",
    "bot_ax.set_ylim([-1,1])\n",
    "\n",
    "_xticks = [0, len(p_contact_corr_rep1_map)-1]\n",
    "bot_ax.set_xticks(_xticks)\n",
    "bot_ax.set_xticklabels(np.round(data_rep1['mid_position_Mb'][_xticks],1))\n",
    "# tick params\n",
    "bot_ax.tick_params('both', labelsize=_font_size-0.5, \n",
    "                width=_ticklabel_width, length=_ticklabel_size-1,\n",
    "                pad=1, labelleft=False, labelbottom=True) # remove bottom ticklabels for ax1\n",
    "[i[1].set_linewidth(_ticklabel_width) for i in bot_ax.spines.items()]\n",
    "# set labels\n",
    "bot_ax.set_xlabel(f'Genomic Positions (Mb)', fontsize=_font_size, labelpad=0)\n",
    "\n",
    "# set limits\n",
    "bot_ax.set_xlim(xlims-0.5)\n",
    "#left_ax.set_ylim([max(ylims)-0.5, min(ylims)-0.5])\n",
    "\n",
    "ax1.set_title(f\"Chr2 P-arm (~1,500 cells)\", fontsize=_font_size+0.5)\n",
    "\n",
    "# save\n",
    "plt.gcf().subplots_adjust(bottom=0.15, left=0.16, right=0.88)\n",
    "\n",
    "plt.savefig(os.path.join(figure_folder, f'Fig2D1_chr2_p_arm_contact_corr_rep1.pdf'), transparent=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lims = [0,len(q_contact_corr_rep1_map)]\n",
    "\n",
    "xlims = np.array([min(lims), max(lims)])\n",
    "ylims = np.array([min(lims), max(lims)])\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "domain_line_color = [1,1,0,1]\n",
    "domain_line_width = 1.5\n",
    "bad_color=[0,0,0,1]\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(_single_col_width, _single_col_width), dpi=600)\n",
    "\n",
    "# create a color map\n",
    "current_cmap = matplotlib.cm.get_cmap('seismic')\n",
    "current_cmap.set_bad(color=[0.5,0.5,0.5,1])\n",
    "\n",
    "_pf = ax1.imshow(q_contact_corr_rep1_map, cmap=current_cmap, vmin=-1, vmax=1)\n",
    "\n",
    "ax1.tick_params('both', labelsize=_font_size, \n",
    "                width=_ticklabel_width, length=0,\n",
    "                pad=1, labelleft=False, labelbottom=False) # remove bottom ticklabels for ax1\n",
    "[i[1].set_linewidth(_ticklabel_width) for i in ax1.spines.items()]\n",
    "\n",
    "\n",
    "# locate ax1\n",
    "divider = make_axes_locatable(ax1)\n",
    "\n",
    "# colorbar ax\n",
    "cax = divider.append_axes('right', size='6%', pad=\"4%\")\n",
    "cbar = plt.colorbar(_pf,cax=cax, ax=ax1, ticks=[-1,1])\n",
    "cbar.ax.tick_params('both', labelsize=_font_size, \n",
    "                width=_ticklabel_width, length=_ticklabel_size-1,\n",
    "                pad=1, labelleft=False) # remove bottom ticklabels for ax1\n",
    "cbar.outline.set_linewidth(_ticklabel_width)\n",
    "cbar.set_label('Pearson correlation', \n",
    "               fontsize=_font_size, labelpad=0, rotation=270)\n",
    "\n",
    "# create bottom ax\n",
    "bot_ax = divider.append_axes('bottom', size='10%', pad=\"0%\", \n",
    "                             sharex=ax1, xticks=[])\n",
    "bot_ax.bar(data_rep1['q_AB_dict']['A']-q_crop.start, height=1, color='r', width=1, label='A')\n",
    "bot_ax.bar(data_rep1['q_AB_dict']['B']-q_crop.start, height=-1, color='b', width=1, label='B')\n",
    "bot_ax.set_yticks([])\n",
    "bot_ax.set_yticklabels([])\n",
    "bot_ax.set_ylim([-1,1])\n",
    "\n",
    "_xticks = [0, len(q_contact_corr_rep1_map)-1]\n",
    "bot_ax.set_xticks(_xticks)\n",
    "bot_ax.set_xticklabels(np.round(data_rep1['mid_position_Mb'][q_crop][_xticks],1))\n",
    "# tick params\n",
    "bot_ax.tick_params('both', labelsize=_font_size-0.5, \n",
    "                width=_ticklabel_width, length=_ticklabel_size-1,\n",
    "                pad=1, labelleft=False, labelbottom=True) # remove bottom ticklabels for ax1\n",
    "[i[1].set_linewidth(_ticklabel_width) for i in bot_ax.spines.items()]\n",
    "# set labels\n",
    "bot_ax.set_xlabel(f'Genomic Positions (Mb)', fontsize=_font_size, labelpad=0)\n",
    "\n",
    "# set limits\n",
    "bot_ax.set_xlim(xlims-0.5)\n",
    "#left_ax.set_ylim([max(ylims)-0.5, min(ylims)-0.5])\n",
    "\n",
    "ax1.set_title(f\"Chr2 Q-arm (~1,500 cells)\", fontsize=_font_size+0.5)\n",
    "\n",
    "# save\n",
    "plt.gcf().subplots_adjust(bottom=0.15, left=0.16, right=0.88)\n",
    "\n",
    "plt.savefig(os.path.join(figure_folder, f'Fig2D2_chr2_q_arm_contact_corr_rep1.pdf'), transparent=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3 density scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# density for the entire chr\n",
    "import multiprocessing as mp\n",
    "num_threads=32\n",
    "density_var = 125 # nm\n",
    "\n",
    "_dna_density_args = [(_zxys,_zxys, data_rep1['AB_dict'], [density_var,density_var,density_var], True) \n",
    "                     for _zxys in data_rep1['dna_zxys']]\n",
    "_dna_density_time = time.time()\n",
    "\n",
    "print(f\"Multiprocessing calculate dna_density_scores\", end=' ')\n",
    "if 'dna_density_scores' not in data_rep1:\n",
    "    with mp.Pool(num_threads) as dna_density_pool:\n",
    "        dna_density_dicts = dna_density_pool.starmap(ia.compartment_tools.scoring.spot_density_scores, _dna_density_args)\n",
    "        dna_density_pool.close()\n",
    "        dna_density_pool.join()\n",
    "        dna_density_pool.terminate()\n",
    "    # save\n",
    "    data_rep1['dna_density_scores'] = dna_density_dicts\n",
    "print(f\"in {time.time()-_dna_density_time:.3f}s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean A.B density scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean A, B density\n",
    "mean_A_scores = np.nanmedian([_s['A'] for _s in data_rep1['dna_density_scores']], axis=0)\n",
    "mean_B_scores = np.nanmedian([_s['B'] for _s in data_rep1['dna_density_scores']], axis=0)\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure(figsize=(_double_col_width, _single_col_width),dpi=600)\n",
    "grid = plt.GridSpec(2, 1, height_ratios=[7,1], hspace=0., wspace=0.2)\n",
    "\n",
    "main_ax = plt.subplot(grid[0], xticklabels=[])\n",
    "\n",
    "main_ax.plot(mean_A_scores, 'r.--', label='A density', markersize=2, linewidth=1)\n",
    "main_ax.plot(mean_B_scores, 'b.--', label='B density', markersize=2, linewidth=1)\n",
    "\n",
    "# ticks\n",
    "main_ax.tick_params('both', labelsize=_font_size, \n",
    "                width=_ticklabel_width, length=_ticklabel_size,\n",
    "                pad=1, labelbottom=False) # remove bottom ticklabels for ax1\n",
    "main_ax.tick_params('x', length=0)\n",
    "[i[1].set_linewidth(_ticklabel_width) for i in main_ax.spines.items()]\n",
    "main_ax.set_ylabel(f\"Mean density scores\", fontsize=_font_size, labelpad=1)\n",
    "\n",
    "handles, labels = main_ax.get_legend_handles_labels()\n",
    "main_ax.legend(handles[::-1], labels[::-1], fontsize=_font_size, loc='upper right')\n",
    "main_ax.set_xlim(0,len(mean_A_scores))\n",
    "\n",
    "comp_ax = plt.subplot(grid[1], xticklabels=[], sharex=main_ax)\n",
    "comp_ax.eventplot([data_rep1['AB_dict']['A'], data_rep1['AB_dict']['B']], lineoffsets=[0.5,-0.5],linelengths=1, linewidths=0.5,\n",
    "                   colors=np.array([[1, 0, 0],[0, 0, 1]]))\n",
    "#comp_ax.imshow(comp_vector[np.newaxis,:], cmap='seismic', vmin=-1, vmax=1)\n",
    "comp_ax.tick_params('both', labelsize=_font_size, \n",
    "                    width=_ticklabel_width, length=_ticklabel_size,\n",
    "                    pad=1, labelbottom=True) # remove bottom ticklabels for ax1\n",
    "[i[1].set_linewidth(_ticklabel_width) for i in comp_ax.spines.items()]\n",
    "\n",
    "comp_ax.set_yticks([0.5,-0.5])\n",
    "comp_ax.set_yticklabels([\"A\",\"B\"])\n",
    "comp_ax.set_ylim([-1,1])\n",
    "_xticks = [0, len(mean_A_scores)-1]\n",
    "comp_ax.set_xticks(_xticks)\n",
    "comp_ax.set_xticklabels(data_rep1['mid_position_Mb'][_xticks])\n",
    "comp_ax.set_xlabel(f'Genomic Positions (Mb)', fontsize=_font_size, labelpad=1)\n",
    "\n",
    "plt.gcf().subplots_adjust(bottom=0.1, left=0.05)\n",
    "\n",
    "plt.savefig(os.path.join(figure_folder, 'FigS2G_chr2_mean_AB_density_rep1.pdf'), transparent=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.4 segregation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize_AB_dict(AB_dict):\n",
    "    all_regs = np.sort(np.concatenate(list(AB_dict.values())))\n",
    "    AB_identities = np.zeros(len(all_regs))\n",
    "    AB_identities[np.array([_i for _i,_r in enumerate(all_regs) \n",
    "                            if _r in AB_dict['A']])] = 1\n",
    "    # randomize new start\n",
    "    new_start = np.random.randint(0, len(all_regs))\n",
    "    new_AB_identities = np.concatenate([AB_identities[new_start:], AB_identities[:new_start]])\n",
    "    # recreate AB_dict\n",
    "    new_AB_dict = {'A': np.sort(all_regs[np.where(new_AB_identities==1)[0]]),\n",
    "                   'B': np.sort(all_regs[np.where(new_AB_identities==0)[0]]),}\n",
    "    return new_AB_dict\n",
    "\n",
    "# calculate dynamic fraction scores\n",
    "from scipy.stats import scoreatpercentile\n",
    "\n",
    "AB_identities_rep1 = np.ones(len(data_rep1['dna_zxys'][0])) * np.nan\n",
    "AB_identities_rep1[data_rep1['AB_dict']['A']] = 1\n",
    "AB_identities_rep1[data_rep1['AB_dict']['B']] = 0\n",
    "\n",
    "from tqdm import tqdm\n",
    "# calculate re-thresholded fraction scores\n",
    "A_fracs, B_fracs = [], []\n",
    "A_ths, B_ths = [], []\n",
    "cloud_th_per=67\n",
    "for _sd in tqdm(data_rep1['dna_density_scores']):\n",
    "    # define A,B threshold based on their own densities\n",
    "    _A_th = scoreatpercentile(_sd['A'][data_rep1['AB_dict']['A']], 100-cloud_th_per)\n",
    "    _B_th = scoreatpercentile(_sd['B'][data_rep1['AB_dict']['B']], 100-cloud_th_per)\n",
    "    # calculate purity within A,B clouds\n",
    "    A_fracs.append(np.nanmean(AB_identities_rep1[np.where(_sd['A'] >= _A_th)[0]]))\n",
    "    B_fracs.append(1-np.nanmean(AB_identities_rep1[np.where(_sd['B'] >= _B_th)[0]]))\n",
    "    # store AB thresholds for references\n",
    "    A_ths.append(_A_th)\n",
    "    B_ths.append(_B_th)\n",
    "# calculate re-thresholded fraction scores\n",
    "rand_A_fracs, rand_B_fracs = [], []\n",
    "\n",
    "for _sd in tqdm(data_rep1['dna_density_scores']):\n",
    "    # randomize AB dict\n",
    "    _rand_AB_dict = randomize_AB_dict(data_rep1['AB_dict'])\n",
    "    _rand_A_inds, _rand_B_inds = np.array(_rand_AB_dict['A']), np.array(_rand_AB_dict['B'])\n",
    "    # generate randomized AB_identities_rep1 vector for purity calculation\n",
    "    _rand_AB_identities_rep1 = np.ones(len(data_rep1['dna_zxys'][0])) * np.nan\n",
    "    _rand_AB_identities_rep1[_rand_AB_dict['A']] = 1\n",
    "    _rand_AB_identities_rep1[_rand_AB_dict['B']] = 0\n",
    "    # define A,B threshold based on their own densities\n",
    "    _A_th = scoreatpercentile(_sd['A'][_rand_A_inds], 100-cloud_th_per)\n",
    "    _B_th = scoreatpercentile(_sd['B'][_rand_B_inds], 100-cloud_th_per)\n",
    "    # calculate purity within A,B clouds\n",
    "    rand_A_fracs.append(np.nanmean(_rand_AB_identities_rep1[np.where(_sd['A'] >= _A_th)[0]]))\n",
    "    rand_B_fracs.append(1-np.nanmean(_rand_AB_identities_rep1[np.where(_sd['B'] >= _B_th)[0]]))\n",
    "\n",
    "# Save\n",
    "data_rep1['segregation_scores'] = (np.array(A_fracs) + np.array(B_fracs)) / 2\n",
    "data_rep1['randomized_segregation_scores'] = (np.array(rand_A_fracs) + np.array(rand_B_fracs)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(figsize=(_single_col_width, _single_col_width),dpi=600)\n",
    "ax.hist(data_rep1['segregation_scores'], 100, range=(0.,1), \n",
    "        density=True, alpha=0.5, \n",
    "        color=[1,0.5,0], label='Chr21')\n",
    "ax.hist(data_rep1['randomized_segregation_scores'], 100, range=(0.,1), \n",
    "        density=True, alpha=0.5, \n",
    "        color=[0.3,0.4,0.4], label='randomized control')\n",
    "\n",
    "ax.legend(fontsize=_font_size-1, loc='upper right')\n",
    "\n",
    "ax.set_xlabel(\"Segregation score\", fontsize=_font_size, labelpad=1)\n",
    "ax.set_ylabel(\"Probability density\", fontsize=_font_size, labelpad=1)\n",
    "\n",
    "ax.tick_params('both', labelsize=_font_size, \n",
    "                width=_ticklabel_width, length=_ticklabel_size,\n",
    "                pad=1, labelleft=True) # remove bottom ticklabels for a_ax\n",
    "[i[1].set_linewidth(_ticklabel_width) for i in ax.spines.items()]\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "ax.set_xlim([0.4,1])\n",
    "\n",
    "plt.gcf().subplots_adjust(bottom=0.15, left=0.15)\n",
    "plt.savefig(os.path.join(figure_folder, 'Fig2F_chr2_segregation_hist_rep1.pdf'), transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From domain interaction to compartments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.5 call domains for chr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import source.domain_tools.DomainAnalysis as da\n",
    "import multiprocessing as mp\n",
    "\n",
    "num_threads=32\n",
    "domain_corr_cutoff = 0.85 \n",
    "domain_dist_cutoff = 1000 # nm\n",
    "\n",
    "_domain_args = [(_zxys, 4, 1000, domain_corr_cutoff, domain_dist_cutoff) \n",
    "                     for _zxys in data_rep1['dna_zxys']]\n",
    "_domain_time = time.time()\n",
    "\n",
    "print(f\"Multiprocessing call domain starts\", end=' ')\n",
    "if 'domain_starts' not in data_rep1:\n",
    "    with mp.Pool(num_threads) as domain_pool:\n",
    "        domain_results = domain_pool.starmap(da.get_dom_starts_cor, _domain_args)\n",
    "        domain_pool.close()\n",
    "        domain_pool.join()\n",
    "        domain_pool.terminate()\n",
    "    # save\n",
    "    data_rep1['domain_starts'] = [np.array(_r[-1]) for _r in domain_results]\n",
    "    data_rep1['params']['domain_corr_cutoff'] = domain_corr_cutoff\n",
    "    data_rep1['params']['domain_dist_cutoff'] = domain_dist_cutoff\n",
    "    \n",
    "print(f\"in {time.time()-_domain_time:.3f}s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## purity histogram and normalized ones\n",
    "_purity_bins = np.linspace(0,1,11)\n",
    "_purity_bin_centers = (_purity_bins[1:] + _purity_bins[:-1])/2\n",
    "\n",
    "AB_identities_rep1 = np.ones(len(data_rep1['dna_zxys'][0])) * np.nan\n",
    "AB_identities_rep1[data_rep1['AB_dict']['A']] = 1\n",
    "AB_identities_rep1[data_rep1['AB_dict']['B']] = 0\n",
    "\n",
    "# calculate purity for p-arm\n",
    "purity_rep1_list = []\n",
    "\n",
    "for _dms in data_rep1['domain_starts']:\n",
    "    _dm_starts = _dms[:-1]\n",
    "    _dm_ends = _dms[1:]\n",
    "    _purities = [np.mean(AB_identities_rep1[_s:_e]) for _s, _e in zip(_dm_starts, _dm_ends)]\n",
    "    purity_rep1_list.append(np.array(_purities))\n",
    "    \n",
    "cmap = matplotlib.cm.seismic\n",
    "bin_colors = cmap(_purity_bin_centers)\n",
    "fig, ax = plt.subplots(figsize=(_single_col_width, _single_col_width),dpi=600)\n",
    "\n",
    "hist_alpha = 1\n",
    "\n",
    "n, hbins, hpatches = ax.hist(np.concatenate(purity_rep1_list), bins=_purity_bins, \n",
    "                             alpha=hist_alpha, density=True, label='total')\n",
    "\n",
    "for _color, _p in zip(bin_colors, hpatches):\n",
    "    plt.setp(_p, 'facecolor', _color)\n",
    "\n",
    "#hab = ax.hist(ama_AB, 24, range=(0,0.6), color='grey', alpha=hist_alpha, density=True, label='AB')\n",
    "#hbb = ax.hist(ama_BB, 24, range=(0,0.6), color='b', alpha=hist_alpha, density=True, label='BB')\n",
    "\n",
    "ax.set_xlabel(\"A region fraction in domain\", fontsize=_font_size, labelpad=1)\n",
    "ax.set_ylabel(\"Probability density\", fontsize=_font_size, labelpad=1)\n",
    "\n",
    "ax.tick_params('both', labelsize=_font_size, \n",
    "                width=_ticklabel_width, length=_ticklabel_size,\n",
    "                pad=1) # remove bottom ticklabels for ax1\n",
    "[i[1].set_linewidth(_ticklabel_width) for i in ax.spines.items()]\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "#ax.legend(fontsize=_font_size, framealpha=1, loc='upper right')\n",
    "ax.set_title(f\"Chr2 domain purity\", pad=3, fontsize=_font_size+1)\n",
    "    \n",
    "plt.gcf().subplots_adjust(left=0.15, bottom=0.15)\n",
    "# save\n",
    "plt.savefig(os.path.join(figure_folder, 'Fig3C_histogram_purity_rep1.pdf'), transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.6: domain interaction calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "num_threads=32\n",
    "# cutoff for:\n",
    "#  domain pairs touching each other -> insulation score <= 2\n",
    "#  domain pairs fully intermix with each other -> insulation score <= 1\n",
    "domain_interact_cutoff = 2\n",
    "domain_intermix_cutoff = 1\n",
    "\n",
    "cutoffs = [domain_intermix_cutoff,domain_interact_cutoff]\n",
    "\n",
    "rep1_interdomain_list = []\n",
    "\n",
    "for _cutoff in cutoffs:\n",
    "    _dom_contact_args = [(_zxys, _domain_starts, _cutoff) \n",
    "                    for _zxys, _domain_starts in zip(data_rep1['dna_zxys'],data_rep1['domain_starts'])]\n",
    "    _domain_time = time.time()\n",
    "\n",
    "    print(f\"Multiprocessing call domain contacts\", end=' ')\n",
    "    with mp.Pool(num_threads) as dom_contact_pool:\n",
    "        dom_contact_results = dom_contact_pool.starmap(ia.domain_tools.interaction.call_domain_contact, _dom_contact_args)\n",
    "        dom_contact_pool.close()\n",
    "        dom_contact_pool.join()\n",
    "        dom_contact_pool.terminate()\n",
    "    rep1_interdomain_list.append(dom_contact_results)\n",
    "    \n",
    "    print(f\"in {time.time()-_domain_time:.3f}s.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AB_identities_rep1 = np.ones(len(data_rep1['dna_zxys'][0])) * np.nan\n",
    "AB_identities_rep1[data_rep1['AB_dict']['A']] = 1\n",
    "AB_identities_rep1[data_rep1['AB_dict']['B']] = 0\n",
    "\n",
    "genomic_dist_mat = squareform(pdist(data_rep1['mid_position_Mb'][:,np.newaxis]))\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "# calculate purity and gdists between each pairs\n",
    "rep1_purity_cutoff_list = []\n",
    "rep1_gdist_cutoff_list = []\n",
    "\n",
    "for _cutoff, _interdomain_list in zip(cutoffs, rep1_interdomain_list):\n",
    "    print(f\"insulation threshold: {_cutoff}\")\n",
    "    pair_purities = []\n",
    "    pair_gdists = []\n",
    "    \n",
    "    for _chrom_id, (_dms, _pairs) in tqdm(enumerate(zip(data_rep1['domain_starts'], _interdomain_list))):\n",
    "        _dm_starts = _dms[:-1]\n",
    "        _dm_ends = _dms[1:]\n",
    "        _purities = [np.mean(AB_identities_rep1[_s:_e]) for _s, _e in zip(_dm_starts, _dm_ends)]\n",
    "        # pairs called in interdomain\n",
    "        for _p in _pairs:\n",
    "            if _p[0] > _p[1]:\n",
    "                _dm_gdist = genomic_dist_mat[int((_dm_starts[_p[0]]+_dm_ends[_p[0]])/2),\n",
    "                                             int((_dm_starts[_p[1]]+_dm_ends[_p[1]])/2)]\n",
    "                _dm_purites = np.array([_purities[_p[0]], _purities[_p[1]]])\n",
    "\n",
    "                # append\n",
    "                pair_purities.append(_dm_purites)\n",
    "                pair_gdists.append(_dm_gdist)\n",
    "                \n",
    "    rep1_purity_cutoff_list.append(np.array(pair_purities))\n",
    "    rep1_gdist_cutoff_list.append(np.array(pair_gdists))\n",
    "\n",
    "    \n",
    "# calculate purity and gdists between all domain candidate pairs, as the denominator\n",
    "rep1_all_purity_pairs = []\n",
    "rep1_all_gdists = []\n",
    "\n",
    "for _chrom_id, _dms in tqdm(enumerate(data_rep1['domain_starts'])):\n",
    "    _dm_starts = _dms[:-1]\n",
    "    _dm_ends = _dms[1:]\n",
    "    _purities = [np.mean(AB_identities_rep1[_s:_e]) for _s, _e in zip(_dm_starts, _dm_ends)]\n",
    "    for _i, (_si, _ei) in enumerate(zip(_dm_starts, _dm_ends)):\n",
    "        for _j, (_sj, _ej) in enumerate(zip(_dm_starts[:_i], _dm_ends[:_i])):\n",
    "            _dm_gdist = genomic_dist_mat[int((_si+_ei)/2),\n",
    "                                         int((_sj+_ej)/2)]\n",
    "            _dm_purites = np.array([_purities[_i], _purities[_j]])\n",
    "            # append\n",
    "            rep1_all_purity_pairs.append(_dm_purites)\n",
    "            rep1_all_gdists.append(_dm_gdist)\n",
    "            \n",
    "rep1_all_purity_pairs = np.array(rep1_all_purity_pairs)\n",
    "rep1_all_gdists = np.array(rep1_all_gdists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain interaction freqeuncy given purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## purity histogram and normalized ones\n",
    "# choose one among the following\n",
    "#_purity_bins = np.array([-1e-5,  0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1+1e-5])\n",
    "#_purity_bins = np.array([-1e-5, 1/8, 2/8, 3/8, 4/8, 5/8, 6/8, 7/8, 1+1e-5])\n",
    "#_purity_bins = np.array([-1e-5, 1/7, 2/7, 3/7, 4/7, 5/7, 6/7, 1+1e-5])\n",
    "_purity_bins = np.array([-1e-5, 1/6, 2/6, 3/6, 4/6, 5/6, 1+1e-5])\n",
    "#_purity_bins = np.array([-1e-5, 0.2, 0.4, 0.6, 0.8, 1+1e-5])\n",
    "\n",
    "_purity_bin_centers = (_purity_bins[1:] + _purity_bins[:-1])/2\n",
    "\n",
    "\n",
    "rep1_purity_count_mat = np.zeros([len(_purity_bin_centers),\n",
    "                                    len(_purity_bin_centers)])\n",
    "# get cutoff=2 case\n",
    "_purity_list = rep1_purity_cutoff_list[-1]\n",
    "_gdist_list = rep1_gdist_cutoff_list[-1]\n",
    "for _pair, _gd in tqdm(zip(_purity_list, _gdist_list)):\n",
    "    _p, _q = _pair\n",
    "    _p_ind = np.where((_p >= _purity_bins[:-1]) & (_p < _purity_bins[1:]))[0][0]\n",
    "    _q_ind = np.where((_q >= _purity_bins[:-1]) & (_q < _purity_bins[1:]))[0][0]\n",
    "    # append\n",
    "    rep1_purity_count_mat[_p_ind,_q_ind] += 1\n",
    "    rep1_purity_count_mat[_q_ind,_p_ind] += 1\n",
    "    \n",
    "rep1_all_purity_count_mat = np.zeros([len(_purity_bin_centers),\n",
    "                                        len(_purity_bin_centers)])\n",
    "for _pair, _gd in tqdm(zip(rep1_all_purity_pairs, rep1_all_gdists)):\n",
    "    _p, _q = _pair\n",
    "    _p_ind = np.where((_p >= _purity_bins[:-1]) & (_p < _purity_bins[1:]))[0][0]\n",
    "    _q_ind = np.where((_q >= _purity_bins[:-1]) & (_q < _purity_bins[1:]))[0][0]\n",
    "    # append\n",
    "    rep1_all_purity_count_mat[_p_ind,_q_ind] += 1\n",
    "    rep1_all_purity_count_mat[_q_ind,_p_ind] += 1\n",
    "\n",
    "# calculate this probability matrix\n",
    "rep1_purity_prob_mat = rep1_purity_count_mat / rep1_all_purity_count_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_limits = [0.23, 0.28]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(_single_col_width, _single_col_width), dpi=_dpi)\n",
    "\n",
    "_pf = ax.imshow(rep1_purity_prob_mat, cmap='seismic', interpolation='nearest',\n",
    "                vmin=min(color_limits), vmax=max(color_limits))\n",
    "\n",
    "ax.tick_params('both', labelsize=_font_size, \n",
    "                width=_ticklabel_width, length=_ticklabel_size,\n",
    "                pad=1, labelbottom=True, labelleft=True) # remove bottom ticklabels for ax\n",
    "[i[1].set_linewidth(_ticklabel_width) for i in ax.spines.items()]\n",
    "\n",
    "ax.set_title(f\"Chr2 rep1\", \n",
    "             fontsize=_font_size, pad=2)\n",
    "\n",
    "# limits\n",
    "_xlims = [-0.5, len(_purity_bins)-1.5]\n",
    "ax.set_ylim(_xlims)\n",
    "ax.set_xlim(_xlims)\n",
    "# ticks\n",
    "_xticks = [-0.5, (len(_purity_bins)-2)/2,  len(_purity_bins)-1.5]\n",
    "_xtick_labels = ['100% B', '50% A/B', '100% A']\n",
    "ax.set_xticks(_xticks)\n",
    "ax.set_xticklabels(_xtick_labels)\n",
    "ax.set_yticks(_xticks)\n",
    "ax.set_yticklabels(_xtick_labels, rotation=90)\n",
    "\n",
    "ax.set_xlabel('Domain A/B composition', labelpad=0, fontsize=_font_size)\n",
    "\n",
    "# locate ax\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "divider = make_axes_locatable(ax)\n",
    "\n",
    "# colorbar ax\n",
    "cax = divider.append_axes('right', size='6%', pad=\"4%\")\n",
    "cbar = plt.colorbar(_pf,cax=cax, ax=ax, ticks=color_limits)\n",
    "cbar.ax.tick_params('both', labelsize=_font_size, \n",
    "                width=_ticklabel_width, length=_ticklabel_size-1,\n",
    "                pad=1, labelleft=False) # remove bottom ticklabels for ax\n",
    "cbar.outline.set_linewidth(_ticklabel_width)\n",
    "cbar.set_label('Domain contact probability', fontsize=_font_size, \n",
    "               labelpad=0, rotation=270)\n",
    "\n",
    "plt.gcf().subplots_adjust(bottom=0.15, left=0.1, right=0.85)\n",
    "\n",
    "plt.savefig(os.path.join(figure_folder, f'Fig3E_chr2_contact_prob_given_purity_rep1_bins-{len(_purity_bins)-1}.pdf'), \n",
    "            transparent=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain interaction freqeuncy given purity and long genomic distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_cutoff = 80 # Mb\n",
    "\n",
    "## purity histogram and normalized ones ( should be same as 3E)\n",
    "#_purity_bins = np.linspace(0,1,11)\n",
    "#_purity_bin_centers = (_purity_bins[1:] + _purity_bins[:-1])/2\n",
    "\n",
    "rep1_purity_high_gd_count_mat = np.zeros([len(_purity_bin_centers),\n",
    "                                    len(_purity_bin_centers)])\n",
    "# get cutoff=2 case\n",
    "_purity_list = rep1_purity_cutoff_list[-1]\n",
    "_gdist_list = rep1_gdist_cutoff_list[-1]\n",
    "for _pair, _gd in tqdm(zip(_purity_list, _gdist_list)):\n",
    "    _p, _q = _pair\n",
    "    _p_ind = np.where((_p >= _purity_bins[:-1]) & (_p < _purity_bins[1:]))[0][0]\n",
    "    _q_ind = np.where((_q >= _purity_bins[:-1]) & (_q < _purity_bins[1:]))[0][0]\n",
    "    if _gd > gd_cutoff:\n",
    "        rep1_purity_high_gd_count_mat[_p_ind,_q_ind] += 1\n",
    "        rep1_purity_high_gd_count_mat[_q_ind,_p_ind] += 1\n",
    "    \n",
    "rep1_all_purity_high_gd_count_mat = np.zeros([len(_purity_bin_centers),\n",
    "                                        len(_purity_bin_centers)])\n",
    "for _pair, _gd in tqdm(zip(rep1_all_purity_pairs, rep1_all_gdists)):\n",
    "    _p, _q = _pair\n",
    "    _p_ind = np.where((_p >= _purity_bins[:-1]) & (_p < _purity_bins[1:]))[0][0]\n",
    "    _q_ind = np.where((_q >= _purity_bins[:-1]) & (_q < _purity_bins[1:]))[0][0]\n",
    "    \n",
    "    if _gd > gd_cutoff:\n",
    "        rep1_all_purity_high_gd_count_mat[_p_ind,_q_ind] += 1\n",
    "        rep1_all_purity_high_gd_count_mat[_q_ind,_p_ind] += 1\n",
    "\n",
    "# calculate this probability matrix\n",
    "rep1_purity_high_gd_prob_mat = rep1_purity_high_gd_count_mat / rep1_all_purity_high_gd_count_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_limits = [0.1, 0.18]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(_single_col_width, _single_col_width), dpi=_dpi)\n",
    "\n",
    "_pf = ax.imshow(rep1_purity_high_gd_prob_mat, cmap='seismic', interpolation='nearest',\n",
    "                vmin=min(color_limits), vmax=max(color_limits))\n",
    "\n",
    "ax.tick_params('both', labelsize=_font_size, \n",
    "                width=_ticklabel_width, length=_ticklabel_size,\n",
    "                pad=1, labelbottom=True, labelleft=True) # remove bottom ticklabels for ax\n",
    "[i[1].set_linewidth(_ticklabel_width) for i in ax.spines.items()]\n",
    "\n",
    "ax.set_title(f\"Chr2 rep1\", \n",
    "             fontsize=_font_size, pad=2)\n",
    "\n",
    "# limits\n",
    "_xlims = [-0.5, len(_purity_bins)-1.5]\n",
    "ax.set_ylim(_xlims)\n",
    "ax.set_xlim(_xlims)\n",
    "# ticks\n",
    "_xticks = [-0.5, (len(_purity_bins)-2)/2,  len(_purity_bins)-1.5]\n",
    "_xtick_labels = ['100% B', '50% A/B', '100% A']\n",
    "ax.set_xticks(_xticks)\n",
    "ax.set_xticklabels(_xtick_labels)\n",
    "ax.set_yticks(_xticks)\n",
    "ax.set_yticklabels(_xtick_labels, rotation=90)\n",
    "\n",
    "ax.set_xlabel('Domain A/B composition', labelpad=0, fontsize=_font_size)\n",
    "\n",
    "# locate ax\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "divider = make_axes_locatable(ax)\n",
    "\n",
    "# colorbar ax\n",
    "cax = divider.append_axes('right', size='6%', pad=\"4%\")\n",
    "cbar = plt.colorbar(_pf,cax=cax, ax=ax, ticks=color_limits)\n",
    "cbar.ax.tick_params('both', labelsize=_font_size, \n",
    "                width=_ticklabel_width, length=_ticklabel_size-1,\n",
    "                pad=1, labelleft=False) # remove bottom ticklabels for ax\n",
    "cbar.outline.set_linewidth(_ticklabel_width)\n",
    "cbar.set_label('Domain contact probability', fontsize=_font_size, \n",
    "               labelpad=0, rotation=270)\n",
    "\n",
    "plt.gcf().subplots_adjust(bottom=0.15, left=0.1, right=0.85)\n",
    "\n",
    "plt.savefig(os.path.join(figure_folder, f'Fig3G_chr2_contact_prob_given_purity_high_gd_rep1_bins-{len(_purity_bins)-1}.pdf'), transparent=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain contact probability given genomic distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 20\n",
    "p_genomic_dist_mat = genomic_dist_mat[p_crop, p_crop]\n",
    "_bins = np.linspace(np.min(p_genomic_dist_mat), \n",
    "                    #np.max(p_genomic_dist_mat), \n",
    "                    200,\n",
    "                    num_bins+1)\n",
    "_bin_centers = (_bins[:-1] + _bins[1:]) / 2\n",
    "A_th = 1.0\n",
    "B_th = 0.0\n",
    "#A_th = 0.9\n",
    "#B_th = 0.1\n",
    "\n",
    "# Fig3F: cutoff = 2\n",
    "_cutoff =  2\n",
    "_index = cutoffs.index(_cutoff)\n",
    "_gdists = rep1_gdist_cutoff_list[_index]\n",
    "_purity_pairs = rep1_purity_cutoff_list[_index]\n",
    "\n",
    "\n",
    "print(_cutoff)\n",
    "nBB,_ = np.histogram(_gdists[(_purity_pairs[:,0] <= B_th) & (_purity_pairs[:,1] <= B_th)],bins=_bins)\n",
    "nAA,_ = np.histogram(_gdists[(_purity_pairs[:,0] >= A_th) & (_purity_pairs[:,1] >= A_th)],bins=_bins)\n",
    "nBB_all,_ = np.histogram(rep1_all_gdists[(rep1_all_purity_pairs[:,0] <= B_th) & (rep1_all_purity_pairs[:,1] <= B_th)],bins=_bins)\n",
    "nAA_all,_ = np.histogram(rep1_all_gdists[(rep1_all_purity_pairs[:,0] >= A_th) & (rep1_all_purity_pairs[:,1] >= A_th)],bins=_bins)\n",
    "nAB,_ = np.histogram(_gdists[(_purity_pairs[:,0] <= B_th)&(_purity_pairs[:,1] >= A_th) \\\n",
    "                             | (_purity_pairs[:,0] >= A_th)&(_purity_pairs[:,1] <= B_th)],bins=_bins)\n",
    "nAB_all,_ = np.histogram(rep1_all_gdists[(rep1_all_purity_pairs[:,0] >= A_th)&(rep1_all_purity_pairs[:,1] <= B_th) \\\n",
    "                                    | (rep1_all_purity_pairs[:,0] <= B_th)&(rep1_all_purity_pairs[:,1] >= A_th)],bins=_bins)\n",
    "\n",
    "fig, ax = plt.subplots(dpi=200, figsize=(_single_col_width, _single_col_width))\n",
    "_line_AA = ax.plot(_bin_centers,nAA/nAA_all,'-o', linewidth=0.75, markersize=2, color='r', label='A-A')\n",
    "_line_BB = ax.plot(_bin_centers,nBB/nBB_all,'-o', linewidth=0.75, markersize=2, color='b', label='B-B')\n",
    "_line_AB = ax.plot(_bin_centers,nAB/nAB_all,'-o', linewidth=0.75, markersize=2, color='grey', label='A-B')\n",
    "\n",
    "ax.tick_params('both', labelsize=_font_size, \n",
    "        width=_ticklabel_width, length=_ticklabel_size,\n",
    "        pad=1,) # remove bottom ticklabels for ax1\n",
    "[i[1].set_linewidth(_ticklabel_width) for i in ax.spines.items()]\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "ax.set_xlim([0, np.max(_bins)])\n",
    "ax.set_ylim([0., 0.7])\n",
    "\n",
    "ax.set_xlabel(f\"Genomic Distance between domains (Mb)\", labelpad=1, fontsize=_font_size)\n",
    "ax.set_ylabel(f\"Domain contact probability\", labelpad=1, fontsize=_font_size)\n",
    "ax.set_title(f\"cutoff={_cutoff:.2f}\", pad=3, fontsize=_font_size+1)\n",
    "\n",
    "ax.legend(loc='upper right',fontsize=_font_size+1)\n",
    "\n",
    "plt.gcf().subplots_adjust(bottom=0.15, left=0.15)\n",
    "plt.savefig(os.path.join(figure_folder, f\"Fig3F_chr2_insulation_genomic_{_cutoff:.2f}_rep1_{A_th}_{B_th}.pdf\"), transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig3H: cutoff = 1\n",
    "_cutoff =  1\n",
    "_index = cutoffs.index(_cutoff)\n",
    "_gdists = rep1_gdist_cutoff_list[_index]\n",
    "_purity_pairs = rep1_purity_cutoff_list[_index]\n",
    "\n",
    "\n",
    "print(_cutoff)\n",
    "nBB,_ = np.histogram(_gdists[(_purity_pairs[:,0] <= B_th) & (_purity_pairs[:,1] <= B_th)],bins=_bins)\n",
    "nAA,_ = np.histogram(_gdists[(_purity_pairs[:,0] >= A_th) & (_purity_pairs[:,1] >= A_th)],bins=_bins)\n",
    "nBB_all,_ = np.histogram(rep1_all_gdists[(rep1_all_purity_pairs[:,0] <= B_th) & (rep1_all_purity_pairs[:,1] <= B_th)],bins=_bins)\n",
    "nAA_all,_ = np.histogram(rep1_all_gdists[(rep1_all_purity_pairs[:,0] >= A_th) & (rep1_all_purity_pairs[:,1] >= A_th)],bins=_bins)\n",
    "nAB,_ = np.histogram(_gdists[(_purity_pairs[:,0] <= B_th)&(_purity_pairs[:,1] >= A_th) \\\n",
    "                             | (_purity_pairs[:,0] >= A_th)&(_purity_pairs[:,1] <= B_th)],bins=_bins)\n",
    "nAB_all,_ = np.histogram(rep1_all_gdists[(rep1_all_purity_pairs[:,0] >= A_th)&(rep1_all_purity_pairs[:,1] <= B_th) \\\n",
    "                                    | (rep1_all_purity_pairs[:,0] <= B_th)&(rep1_all_purity_pairs[:,1] >= A_th)],bins=_bins)\n",
    "\n",
    "fig, ax = plt.subplots(dpi=200, figsize=(_single_col_width, _single_col_width))\n",
    "_line_AA = ax.plot(_bin_centers,nAA/nAA_all,'-o', linewidth=0.75, markersize=2, color='r', label='A-A')\n",
    "_line_BB = ax.plot(_bin_centers,nBB/nBB_all,'-o', linewidth=0.75, markersize=2, color='b', label='B-B')\n",
    "_line_AB = ax.plot(_bin_centers,nAB/nAB_all,'-o', linewidth=0.75, markersize=2, color='grey', label='A-B')\n",
    "\n",
    "ax.tick_params('both', labelsize=_font_size, \n",
    "        width=_ticklabel_width, length=_ticklabel_size,\n",
    "        pad=1,) # remove bottom ticklabels for ax1\n",
    "[i[1].set_linewidth(_ticklabel_width) for i in ax.spines.items()]\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "ax.set_xlim([0, np.max(_bins)])\n",
    "ax.set_ylim([0., 0.06])\n",
    "\n",
    "ax.set_xlabel(f\"Genomic Distance between domains (Mb)\", labelpad=1, fontsize=_font_size)\n",
    "ax.set_ylabel(f\"Domain contact probability\", labelpad=1, fontsize=_font_size)\n",
    "ax.set_title(f\"cutoff={_cutoff:.2f}\", pad=3, fontsize=_font_size+1)\n",
    "\n",
    "ax.legend(loc='upper right',fontsize=_font_size+1)\n",
    "\n",
    "plt.gcf().subplots_adjust(bottom=0.15, left=0.15)\n",
    "plt.savefig(os.path.join(figure_folder, f\"Fig3H_chr2_insulation_genomic_{_cutoff:.2f}_rep1_{A_th}_{B_th}.pdf\"), transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
